# src/services/agents.py

import glob
from typing import Callable, Dict, List, Tuple
from src.services.llm_old2 import LLM
import re
import os


class Tool:
    """Represents a tool that the Agent can use to perform actions.

    Attributes:
        name (str): Name of the tool.
        func (Callable): Function to execute when this tool is called.
        description (str): Short description of what the tool does.
    """

    def __init__(self, name: str, func: Callable, description: str = ""):
        self.name = name
        self.func = func
        self.description = description


class Agent:
    """An Agent that interacts with an LLM and uses tools to answer queries.

    Attributes:
        llm (LLM): The language model instance used for generating responses.
        tools (Dict[str, Tool]): Dictionary of available tools.
        prompt_template (str): Prompt template loaded from a file.
        max_steps (int): Maximum number of reasoning steps before returning an answer.
        verbose (bool): Whether to print prompts and intermediate steps.
    """

    def __init__(
        self,
        llm: LLM,
        tools: List[Tool],
        prompt_file: str,
        max_steps: int = 100,
        max_actions_per_step: int = 5,
        verbose: bool = True,
        scratchpad_path: str = None,
    ):
        """Initializes the Agent.

        Args:
            llm (LLM): The LLM instance to use.
            tools (List[Tool]): List of tools available to the agent.
            prompt_file (str): Path to the prompt template file.
            max_steps (int, optional): Maximum reasoning steps. Defaults to 5.
            verbose (bool, optional): Whether to print prompts and outputs. Defaults to True.
        """
        self.llm = llm
        self.tools: Dict[str, Tool] = {t.name: t for t in tools}
        self.verbose = verbose
        self.max_steps = max_steps
        self.scratchpad_path = scratchpad_path
        self.max_actions_per_step = max_actions_per_step

        # Load the prompt template
        with open(prompt_file, "r", encoding="utf-8") as f:
            self.prompt_template = f.read()

    def run(self, query: str) -> str:
        """Run the agent to answer a query using the LLM and available tools.

        Args:
            query (str): The user query to answer.

        Returns:
            str: The final answer generated by the agent.
        """
        if self.scratchpad_path != None:
            scratchpad = (
                open(self.scratchpad_path, "r").read()
                if os.path.exists(self.scratchpad_path)
                else ""
            )
        for step in range(self.max_steps):
            # Fill in the prompt template
            prompt = self.prompt_template.format(
                tools_description="\n".join(
                    f"{t.name} -> {t.description}" for t in self.tools.values()
                ),
                tools_list=", ".join(self.tools.keys()),
                input=query,
                agent_scratchpad=scratchpad,
                max_actions_per_step=self.max_actions_per_step,
            )

            if self.verbose:
                print(f"\n=== Prompt step {step+1} ===\n")

            # Query the LLM
            llm_output = self.llm.query(prompt, verbose=self.verbose)

            # Parse LLM output: returns list of (action, thought, action_input)
            actions_list = parse_llm_output(llm_output)

            # Iterate over each action
            for action, thought, action_input in actions_list:
                result = ""
                if action and action in self.tools:
                    try:
                        result = self.tools[action].func(action_input)
                    except Exception as e:
                        result = f"Tool '{action}' execution failed: {e}"

                # Update scratchpad for each action
                scratchpad += (
                    f"[\n"
                    f"Thought: ~~~{thought}~~~\n"
                    f"Action: ~~~{action}~~~\n"
                    f"Action Input: ~~~{action_input}~~~\n"
                    f"Action Result: ~~~{result}~~~\n"
                    f"]\n"
                )

                if self.scratchpad_path != None:
                    open(self.scratchpad_path, "w", encoding="utf-8").write(scratchpad)

        # Return the last LLM output if max_steps exceeded
        return llm_output.strip()


def parse_llm_output(text: str) -> List[Tuple[str, str, str]]:
    """Parse the LLM output to extract all actions with thought and action input."""
    pattern = (
        r"Thought:\s*~~~(.*?)~~~\s*"
        r"Action:\s*~~~(.*?)~~~\s*"
        r"Action Input:\s*~~~(.*?)~~~"
    )

    matches = re.findall(pattern, text, flags=re.DOTALL | re.IGNORECASE)

    # strip whitespace for each part
    result = [(a.strip(), t.strip(), i.strip()) for t, a, i in matches]

    return result
